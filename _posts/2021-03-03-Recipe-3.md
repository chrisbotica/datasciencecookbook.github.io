---
layout: post
title: "Recipe 3: Setting Up Your Data"
date: 2019-03-03
permalink: /recipe3/
---
## Understanding your Data

<br><br><br><br>
### Structured vs. Unstructured Data
Not all data is created equal, not all data is relevant to your problem, and not all data is usable. You must first understand the structure of your data before beginning your problem.

Structured data is often quantitative. It is organized neatly in rows and columns (like a spreadsheet or a table. It may be referred to as tabular data. These data are often stored in .xlsx and .csv files or a relational database. Relational databases can be accessed through Structured Query Language (SQL). An example of structured data may be a list of customers, their addresses, phone numbers, and products they’ve ordered.

Relational databases are great for performing quick searches because they are well-structured. However, this structure can be a detriment. If your data schema (the structure of your database or fields of data collect) changes, your relational database will not easily support this change. Relational databases are also not good for unstructured data.

<br><br>
![Structured Data](/assets/recipe3/structured_data.png)

<br><br>
Unstructured data is usually not quantitative or easily stored in tables, or the fields may change. Examples include images, audio files, video, social media, activity, and text documents (things that don’t fit well in a spreadsheet). These data are better stored in non-relational databases (sometimes called NoSQL databases), which have more flexibility in storage (and changes in the type of data you collect) at a trade-off for speed of search.

<br><br>
### Labeled vs. Unlabeled Data Data
Now that you’ve got data in a database, you need to understand whether it is labeled or not. If you have labeled data, you can do supervised machine learning. If your data is not labeled, you can either label it or do unsupervised learning.

Most machine learning focuses on supervised learning. The idea is that the machine learns by having a teacher oversee the process. For every prediction the machine makes using the training data, there is a label indicating the correct answer. The constant feedback allows the machine to learn from these data and then make predictions using future data. Supervised learning problems are either classification (predicting whether this piece of data belongs to one class or another) or regression (predicting a continuous variable like housing price, test score, or temperature). Labels can come in the form of a filename, a column in a spreadsheet, or a folder where you keep all the data of a certain type.

If the data isn’t labeled, or you’re more interested in clustering and similarity than prediction, unsupervised learning can help. Unsupervised learning is often less about finding the “right answer” and more about trying to understand your data. Unsupervised learning is great for clustering similar things (like groups of people based on behavior / survey responses) (example image below).

<br><br>
![Clustering Example](/assets/recipe3/kmeans.png)

<br/><br/>
![Examples of Data Problems](/assets/recipe3/examples_of_data_problems_table.png)

<br><br>
## Data Labeling
For many real world projects you have data but no labels. Data labeling can be one of the biggest bottlenecks in any machine learning project. How you choose to label your ‘ground truth’ data will depend on the expertise required to label the data, the size of the labeling task relative to your available team, the system/platform you have to label data on, and how much money you are willing to spend on data. Here are a few options:

#### Do it yourself
Manual data labeling is time consuming and boring, but if you don’t have a team of people to help you or much money to spend it may be the best way to get your project off the ground. Sometimes it’s just you and an excel workbook.

#### Public Crowd (Mechanical Turk)
Amazon Mechanical Turk is a platform that allows for the crowdsourcing of data sets. It’s relatively cheap on a per-label basis, but labelers are likely not an expert on your problem so their labels may be inaccurate and need to be quality-assured.

#### Private Crowd
A private crowd may have more training than a public crowd, but costs considerably more. There are plenty of companies that offer this as a service. This is an option when your labeling requires some expertise that is trainable (and you can do quality-assurance on the company’s labels) but the labeling task is still too big to accomplish with your internal resources. Be careful, some vendors may keep your data and the labels for their own use/sales.

#### Use Subject Matter Experts
If you want the best possible labels on satellite imagery, use trained imagery analysts. If you want the best labels of medical imagery, use doctors. Though expert labelers have the highest quality they often are expensive or strapped for time.

#### Data Labeling Platform
If you have expert labelers but no efficient way of letting them apply their knowledge to the data, you have a problem. One way to take advantage of your organization’s subject matter expertise is leveraging a data labeling platform. This is basically a software product specially built to make labeling easier for your experts (more focus on labeling instead of navigating your labeling system).

#### Labeling Functions
If you have more data than your team of experts can hand-label, one option is to use labeling functions. Snorkel, an open-source project from Stanford is great for this. You can use the expert knowledge to write labeling functions that will apply ‘pseudo-labels’ using heuristics. Then, a model is created to learn the accuracies of the labeling functions and reweight/combine/choose among the pseudo-labels to create a single training label per data point. If desired, these pseudo labels can be improved by creating a small set of ‘gold standard’ labels. Snorkel has been used in high-profile research papers in the medical community. Some tutorials can be found here.

#### Semi-automated Data Labeling
If you already have trained, or have access to, a performant prediction model for your use case, one approach is to introduce automation into your data labeling workflow by using model inference predictions as a form of “pre-labels” for raw data. Depending on the use case, this can significantly accelerate the time it takes to generate machine learning training data. These “pre-labels” should almost always be reviewed and adjusted by a human labeler to verify accuracy. There are many ways to sequence this workflow but a simple application is to generate predictions from a single model as an initial labeling stage and route all the outputs to a human labeler for review. The human would then be adding, verifying, or adjusting machine-generated “pre-labels” rather than only applying new labels to raw data.
