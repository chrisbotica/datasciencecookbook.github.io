---
layout: post
title: "Recipe 10: From model.predict() to Prototype"
date: 2012-10-10
---
Okay, you’ve done the hard part. Formulating a problem, acquiring and labeling data, cleaning it, building a naive baseline model, then beating that model. You now have an accurate model that you’re proud of, but is still mostly useless to your user. You need to build a prototype to show your work. Sharing a GitHub repo or script isn’t going to cut it. Here are a few options from lowest to greatest fidelity.

<br><br>
### Option 1: Jupyter  Notebook
Delivering a jupyter notebook to the end user is the fastest and easiest way to provide a data science tool. If you  are trying to build an interactive data science tool for your end user (for instance to make predictions off of new data), this may be a good option for an initial prototype. There are many tricks you can use to minimize code-user interactions and make it more polished. A combination of ipywidgets and html code in your notebook can hide non-user friendly code and only display the buttonology needed to navigate the workflow. If users are running the notebook from local machines, you should create a package’s requirements file to ensure environments are loaded correctly.

While a jupyter notebook can be a useful initial prototype display, regardless of how many set up and running instructions you create, it still requires the user to have all software and dependencies installed and  be comfortable navigating jupyter. Furthermore, it runs the risk of file corruption and can not be easily integrated into complex workflows.  Depending on network restrictions, you could hypothetically also use pyinstaller to create an executable file that wraps up all required packages. However, this generally runs into approval difficulty with network managers.  As a result, when a problem requires a quick solution or you have limitations in access to servers or cloud environments, a jupyter notebook can be a reliable solution.

You can also make jupyter notebooks interactive. Here’s a [tutorial](https://towardsdatascience.com/interactive-visualizations-in-jupyter-notebook-3be02ab2b8cd) and another for [ipywidget](https://towardsdatascience.com/bring-your-jupyter-notebook-to-life-with-interactive-widgets-bc12e03f0916).

<br><br>
### Option 2: Streamlit + Heroku
Many data scientists aren’t good at building applications. [Streamlit](https://streamlit.io/) helps translate Python scripts into easy-to-render visuals or webpages with pretty little overhead. And you can deploy straight from your GitHub repo!

Streamlit is a PyPI library that allows you to use .py scripts to write to a streamlit application. It’s great for visualization and allows for interaction using sliders, text-entry, file upload, and more.

Here are some [Streamlit demos](https://streamlit.io/gallery?type=apps&category=featured). We’ve also shared screen-grabs of [NYC Uber Rideshare Pickup Data](https://share.streamlit.io/streamlit/demo-uber-nyc-pickups/), computer vision for [chest x-ray analysis](https://share.streamlit.io/ashishthomaschempolil/medical-image-captioning-on-chest-x-rays/main/final.py), and a [NFL Wide Receiver Dashboard](https://share.streamlit.io/maxbolger/nfl-receiver-dashboard/main/receiver-dashboard.py).

<br><br>
![Streamlit NYC Uber](/assets/recipe10/streamlit_rideshare_nyc.png)

<br><br>
![Streamlit Chest x-ray](/assets/recipe10/streamlit_chest_xray.png)

<br><br>
![Streamlit Wide Receiver Dashboard](/assets/recipe10/streamlit_wide_receiver.png)

<br><br>

Here’s a TDS [guide to building a Streamlit app](https://towardsdatascience.com/data-analytics-to-web-app-streamlit-made-easy-ed687266f0e8), the very helpful [Streamlit documentation](https://docs.streamlit.io/en/stable/), [getting started tutorial](https://docs.streamlit.io/en/stable/getting_started.html), [API](https://docs.streamlit.io/en/stable/api.html). If you’re not comfortable using the documentation, [Coursera offers a guided course on creating a data science app with Streamlit](https://www.coursera.org/projects/data-science-streamlit-python).

When you’re ready to deploy your app from your local machine to the web, you can check out their [deployment instructions](https://docs.streamlit.io/en/stable/deploy_streamlit_app.html). This allows streamlit to use your public GitHub repo for deployment. Other options (AWS, Google Cloud, Heroku, as a standalone executable) are also available with [community-created guidelines](https://discuss.streamlit.io/t/streamlit-deployment-guide-wiki/5099) here.

<br><br>
### Option 3: A Web App
A web application, or a mobile application, could be what a customer actually envisions when they ask you to solve their Machine Learning/Data Science problem. While this may not be attractive to most organizations that are more heavy in data science/analytics and not in web and mobile app developers, it is necessary evil to solve technology problems for a customer that prefers an easy, accessible solution. In this case, opt for easy front-end libraries that can connect to a nice, formatted API model. This is going to require a bigger team -- people that can take the output of a ML model, format it to be some JSON or other type of thing that can be easily transferred and then depicted in a visual way (whether it be a graphic or just text on a webpage), and someone to then “beautify” the front-end. Not an easy endeavor for the casual data group, but if it can be afforded, some solid managers will be extremely important.

To do this, you'll need to:
- Save your model
- [Deploy as an API](https://towardsdatascience.com/deploying-a-machine-learning-model-as-a-rest-api-4a03b865c166)
    - Another article [here](https://towardsdatascience.com/how-to-easily-deploy-machine-learning-models-using-flask-b95af8fe34d4)
- Connect API to front-end
- Containerize


<br><br>
### Option 4: Software, Programs, and Executables

This is one of the longest living and traditional methods for computer based tools to be deployed in the DoD.  However, it is not the recommended solution. The pros of using this are that the end user can just click the program and run your data science tool on their local machine without  knowledge of programming, development environment access, or network connections.

However the cons are that it is rarely lightweight and will likely be memory intensive  on local machines. In addition, it requires a lot more user interface development and software development skills. Version control and maintenance will also be more difficult.  More importantly, your cyber security manager might have a hernia when they find random executables and programs on their computers (more likely it will just be blocked from running). If you have the leeway to create and run programs on local machines and are not concerned with memory costs on local machines, this is the way to go.

To create an executable in Python you can use [Pyinstaller](https://realpython.com/pyinstaller-python/). It turns  your scripts into an application by wrapping up all the dependencies into something shareable across machines.
